{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fd9761-43c3-4667-b5d0-a41fa061ae06",
   "metadata": {},
   "source": [
    "# Extracting Data via API Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142b96d-2162-4be6-85e6-0e6672fb069b",
   "metadata": {},
   "source": [
    "# Load Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c0975-1c39-4c0e-84e5-488fc0f87970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.metrics import specificity_score, sensitivity_score\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import spacy\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "# Download necessary NLTK data\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d5634-d635-464a-8c93-b43da45f356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some additional workflow settings\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a95c4-b547-4013-9a39-02583628e1a7",
   "metadata": {},
   "source": [
    "# Call Data from Clinicaltrial.gov API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7b7b9-6531-4d44-83c8-8caafd9221a2",
   "metadata": {},
   "source": [
    "## Do a Test Call to API to check for bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768cace-5024-42c6-90ab-ef3d811030f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the API\n",
    "base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "\n",
    "# Define the query parameters and desired fields\n",
    "params = {\n",
    "    'format': 'json',\n",
    "    'postFilter.overallStatus': 'COMPLETED',\n",
    "    'postFilter.advanced': '(AREA[StudyType]INTERVENTIONAL OR OBSERVATIONAL) AND (AREA[Sex]MALE OR AREA[Sex]FEMALE)',\n",
    "    'fields': 'NCTId|Condition|StartDate|PrimaryCompletionDate|BriefSummary|EnrollmentCount|Sex|MinimumAge|MaximumAge',\n",
    "    'pageSize': 3  # Limit to 3 records for testing\n",
    "}\n",
    "\n",
    "# Function to make the API call\n",
    "def fetch_clinical_trials(params):\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers={\"accept\": \"application/json\"})\n",
    "        # Print the final URL to debug any issues with the query parameters\n",
    "        print(f\"Request URL: {response.url}\")\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch the data and print it to test the connection\n",
    "data = fetch_clinical_trials(params)\n",
    "\n",
    "# Check if data was retrieved successfully\n",
    "if data:\n",
    "    # Print the JSON data\n",
    "    print(json.dumps(data, indent=2))\n",
    "else:\n",
    "    print(\"No data retrieved or error occurred.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e5ff8-7738-4085-9dab-fc2583dd9222",
   "metadata": {},
   "source": [
    "## Run full call to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23802b93-aa52-483e-9dca-fe42f6b9b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the API\n",
    "base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "\n",
    "# Define the query parameters and desired fields\n",
    "params = {\n",
    "    'format': 'json',\n",
    "    'postFilter.overallStatus': 'COMPLETED',\n",
    "    'postFilter.advanced': '(AREA[StudyType]INTERVENTIONAL OR OBSERVATIONAL)',\n",
    "    'fields': 'NCTId|Condition|StartDate|PrimaryCompletionDate|BriefSummary|EnrollmentCount|Sex|MinimumAge|MaximumAge',\n",
    "    'pageSize': 1000  # Number of records to fetch per request\n",
    "}\n",
    "\n",
    "# Function to make the API call\n",
    "def fetch_clinical_trials(params):\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers={\"accept\": \"application/json\"})\n",
    "        # Print the final URL to debug any issues with the query parameters\n",
    "        #print(f\"Request URL: {response.url}\")\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            print(\"API call successful\")\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract relevant data from the API response\n",
    "def extract_study_data(study):\n",
    "    protocol_section = study.get('protocolSection', {})\n",
    "    identification_module = protocol_section.get('identificationModule', {})\n",
    "    status_module = protocol_section.get('statusModule', {})\n",
    "    description_module = protocol_section.get('descriptionModule', {})\n",
    "    conditions_module = protocol_section.get('conditionsModule', {})\n",
    "    design_module = protocol_section.get('designModule', {})\n",
    "    eligibility_module = protocol_section.get('eligibilityModule', {})\n",
    "\n",
    "    # Exclude records where sex or brief summary is not available\n",
    "    if 'sex' not in eligibility_module or 'briefSummary' not in description_module:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        'NCTId': identification_module.get('nctId', 'N/A'),\n",
    "        'Condition': conditions_module.get('conditions', ['N/A']),\n",
    "        'StartDate': status_module.get('startDateStruct', {}).get('date', 'N/A'),\n",
    "        'PrimaryCompletionDate': status_module.get('primaryCompletionDateStruct', {}).get('date', 'N/A'),\n",
    "        'BriefSummary': description_module.get('briefSummary', 'N/A'),\n",
    "        'EnrollmentCount': design_module.get('enrollmentInfo', {}).get('count', 'N/A'),\n",
    "        'Sex': eligibility_module.get('sex', 'N/A'),\n",
    "        'MinimumAge': eligibility_module.get('minimumAge', 'N/A'),\n",
    "        'MaximumAge': eligibility_module.get('maximumAge', 'N/A')\n",
    "    }\n",
    "\n",
    "# Fetch and process the data with a delay between requests and avoid duplicates\n",
    "def fetch_and_process_data(params, max_requests):  # Increase max_requests for more data retrieval\n",
    "    all_extracted_data = []\n",
    "    seen_nct_ids = set()\n",
    "    next_page_token = None\n",
    "\n",
    "    for _ in range(max_requests):\n",
    "        if next_page_token:\n",
    "            params['pageToken'] = next_page_token\n",
    "\n",
    "        data = fetch_clinical_trials(params)\n",
    "        if data:\n",
    "            studies = data.get('studies', [])\n",
    "            next_page_token = data.get('nextPageToken', None)\n",
    "\n",
    "            print(f\"Number of studies fetched: {len(studies)}\")  # Debugging statement\n",
    "            for study in studies:\n",
    "                nct_id = study.get('protocolSection', {}).get('identificationModule', {}).get('nctId')\n",
    "                if nct_id and nct_id not in seen_nct_ids:\n",
    "                    seen_nct_ids.add(nct_id)\n",
    "                    extracted_data = extract_study_data(study)\n",
    "                    all_extracted_data.append(extracted_data)\n",
    "                    #print(json.dumps(extracted_data, indent=2))  # Debugging statement\n",
    "                else:\n",
    "                    print(f\"Duplicate or missing NCTId: {nct_id}\")\n",
    "\n",
    "            if not next_page_token:\n",
    "                break  # No more pages to fetch\n",
    "\n",
    "        # Pause the execution for a short, random period of time to avoid overwhelming the server\n",
    "        time.sleep(5 + 10 * random.random())\n",
    "    \n",
    "    return all_extracted_data\n",
    "\n",
    "# Fetch data for random sample of MALE or FEMALE studies\n",
    "random_sample_params = params.copy()\n",
    "random_sample_params['postFilter.advanced'] += ' AND (AREA[Sex]MALE OR AREA[Sex]FEMALE)'\n",
    "random_sample_studies = fetch_and_process_data(random_sample_params, max_requests=15)\n",
    "\n",
    "# Combine both sets of data\n",
    "all_data = random_sample_studies \n",
    "\n",
    "print(\"Data fetching and processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eeb829-bbdf-42da-9eec-41fba0329ce2",
   "metadata": {},
   "source": [
    "## Save Raw API Data as .csv and .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288d3f3-1fa9-4407-868d-1e8bf7a91e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the extracted data to a DataFrame\n",
    "all_df = pd.DataFrame(all_data)\n",
    "\n",
    "# Create a new folder called \"data_files\"\n",
    "os.makedirs(\"raw_data_files\", exist_ok=True)\n",
    "\n",
    "# Save DataFrame to a CSV file in the \"data_files\" folder\n",
    "all_df.to_csv(os.path.join(\"raw_data_files\", \"clinical_trials.csv\"), index=False)\n",
    "\n",
    "# Save the data to a JSON file in the \"data_files\" folder\n",
    "with open(os.path.join(\"raw_data_files\", \"clinical_trials.json\"), 'w') as outfile:\n",
    "    json.dump(all_data, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af141f0-015e-4b3d-a0af-6cc67e23ec20",
   "metadata": {},
   "source": [
    "# Call Data from PUBMED Entrez API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f014d7d-a72a-4ede-9575-cf69b294feec",
   "metadata": {},
   "source": [
    "## Do a Test Call to API to check for bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476678a6-8df0-40c0-8283-f2afb21669fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b63aa0d-9115-407a-b725-2f6963195304",
   "metadata": {},
   "source": [
    "## Run full call to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a3c70-f3b5-4369-91eb-0c21305fc67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the API\n",
    "base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "\n",
    "# Define the query parameters and desired fields\n",
    "params = {\n",
    "    'db': 'pubmed',\n",
    "    'term': 'completed[Title/Abstract] AND (interventional[Filter] OR observational[Filter])',\n",
    "    'retmode': 'json',\n",
    "    'retmax': 1000,  # Number of records to fetch per request\n",
    "}\n",
    "\n",
    "# Function to make the API call to get IDs\n",
    "def fetch_pubmed_ids(params):\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            print(\"API call successful\")\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch the details for the IDs retrieved\n",
    "def fetch_pubmed_details(ids):\n",
    "    details_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
    "    details_params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': ','.join(ids),\n",
    "        'retmode': 'json',\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(details_url, params=details_params)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Details API call successful\")\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve details: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Details request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract relevant data from the API response\n",
    "def extract_study_data(study):\n",
    "    return {\n",
    "        'Id': study.get('uid', 'N/A'),\n",
    "        'Title': study.get('title', 'N/A'),\n",
    "        'Source': study.get('source', 'N/A'),\n",
    "        'PubDate': study.get('pubdate', 'N/A'),\n",
    "        'Authors': [author['name'] for author in study.get('authors', [])],\n",
    "        'Abstract': study.get('elocationid', 'N/A'),\n",
    "        'Volume': study.get('volume', 'N/A'),\n",
    "        'Issue': study.get('issue', 'N/A'),\n",
    "        'Pages': study.get('pages', 'N/A')\n",
    "    }\n",
    "\n",
    "# Fetch and process the data\n",
    "def fetch_and_process_data(params, max_requests=15):  # Increase max_requests for more data retrieval\n",
    "    all_extracted_data = []\n",
    "    next_page_token = None\n",
    "\n",
    "    for _ in range(max_requests):\n",
    "        if next_page_token:\n",
    "            params['pageToken'] = next_page_token\n",
    "\n",
    "        data = fetch_pubmed_ids(params)\n",
    "        if data:\n",
    "            ids = data.get('esearchresult', {}).get('idlist', [])\n",
    "            next_page_token = data.get('esearchresult', {}).get('next_page_token', None)\n",
    "\n",
    "            if ids:\n",
    "                details = fetch_pubmed_details(ids)\n",
    "                studies = details.get('result', {}).get('uids', [])\n",
    "                \n",
    "                for study_id in studies:\n",
    "                    study = details['result'][study_id]\n",
    "                    extracted_data = extract_study_data(study)\n",
    "                    all_extracted_data.append(extracted_data)\n",
    "\n",
    "            if not next_page_token:\n",
    "                break  # No more pages to fetch\n",
    "\n",
    "        # Pause the execution for a short, random period of time to avoid overwhelming the server\n",
    "        time.sleep(5 + 10 * random.random())\n",
    "    \n",
    "    return all_extracted_data\n",
    "\n",
    "# Fetch data\n",
    "random_sample_studies = fetch_and_process_data(params, max_requests=15)\n",
    "\n",
    "# Combine both sets of data\n",
    "all_data = random_sample_studies \n",
    "\n",
    "print(\"Data fetching and processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5fdae-e8e6-4181-b346-04dffefc1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data\n",
    "\n",
    "# Save DataFrame to a CSV file in the \"data_files\" folder\n",
    "all_df.to_csv(os.path.join(\"raw_data_files\", \"clinical_trials.csv\"), index=False)\n",
    "\n",
    "# Save the data to a JSON file in the \"data_files\" folder\n",
    "with open(os.path.join(\"raw_data_files\", \"clinical_trials.json\"), 'w') as outfile:\n",
    "    json.dump(all_data, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d3f40-4865-43dc-8afc-cb24010a6e53",
   "metadata": {},
   "source": [
    "# Data Wrangling to Standardize Features from Both Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57abc38-d664-426e-a974-872c49843e04",
   "metadata": {},
   "source": [
    "### Clinical Trial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ceb102-63ad-4250-bc6f-c681ef7947d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08bc8d-85d0-435c-a10a-4499519f3e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21674c-ba9c-4621-8602-e00722c5e2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "736662f5-ac2b-4144-9c60-da423d4a6fed",
   "metadata": {},
   "source": [
    "### PUBMED Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a9faf-70db-4a15-affd-ccd33fdf068c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8fa29-7682-47f5-8993-53872d9f387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97fc9a-8987-43c6-a7b5-addfb967166d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46142dfa-9cfd-41ab-8da7-fec6955d2852",
   "metadata": {},
   "source": [
    "### Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16147df2-0cab-4871-9e19-7bf343f21479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2386a-1a18-411a-ba97-45fa4d3fbba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
